{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNoWzQzTrjJRryXFiwTF4C0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dnaae/minor-internship/blob/FISH-QUANT-pipeline/Coordinates_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install big-fish"
      ],
      "metadata": {
        "id": "IEoo3_lt9FjB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8bbemzwZ88Ri"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import bigfish\n",
        "import bigfish.stack as stack\n",
        "import bigfish.classification as classification\n",
        "import bigfish.plot as plot\n",
        "from google.colab import drive\n",
        "import re\n",
        "print(\"Big-FISH version: {0}\".format(bigfish.__version__))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to mount Google Drive and select a folder\n",
        "def choose_folder_colab():\n",
        "    drive.mount('/content/drive')\n",
        "    drive_folder = \"/content/drive/MyDrive/\"\n",
        "    contents = os.listdir(drive_folder)\n",
        "\n",
        "    print(\"Contents of your Google Drive:\")\n",
        "    for i, item in enumerate(contents):\n",
        "        print(f\"{i + 1}: {item}\")\n",
        "\n",
        "    while True:\n",
        "        choice = input(\"Enter the number of the folder you want to select (q to quit): \")\n",
        "        if choice.lower() == 'q':\n",
        "            return None\n",
        "        try:\n",
        "            choice = int(choice)\n",
        "            if 1 <= choice <= len(contents):\n",
        "                selected_folder = os.path.join(drive_folder, contents[choice - 1])\n",
        "                return selected_folder\n",
        "            else:\n",
        "                print(\"Invalid choice. Please try again or enter 'q' to quit.\")\n",
        "        except (ValueError, KeyboardInterrupt):\n",
        "            print(\"Invalid input. Please try again or enter 'q' to quit.\")"
      ],
      "metadata": {
        "id": "TZFYCMlY9iul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def distance_feature_names():\n",
        "    feature_names =  classification.get_features_name(names_features_distance=True)\n",
        "    return feature_names"
      ],
      "metadata": {
        "id": "fiXPldS39r8_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def intranuclear_feature_names():\n",
        "  feature_names=classification.get_features_name(names_features_intranuclear=True)\n",
        "  return feature_names"
      ],
      "metadata": {
        "id": "5-ZJwbmw9uWz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def protrusion_feature_names():\n",
        "  feature_names = classification.get_features_name(names_features_protrusion=True)\n",
        "  return feature_names"
      ],
      "metadata": {
        "id": "_woBltWz9wc1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dispersion_feature_names():\n",
        "  feature_names = classification.get_features_name(names_features_dispersion=True)\n",
        "  return feature_names"
      ],
      "metadata": {
        "id": "rWMVkkZ89yi0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def topographic_feature_names():\n",
        "  feature_names = classification.get_features_name(names_features_topography=True)\n",
        "  return feature_names"
      ],
      "metadata": {
        "id": "XJEBc2n590s2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def foci_feature_names():\n",
        "  feature_names = classification.get_features_name(names_features_foci=True)\n",
        "  return feature_names"
      ],
      "metadata": {
        "id": "3lG5H81I93Nf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def area_feature_names():\n",
        "  feature_names = classification.get_features_name(names_features_area=True)\n",
        "  return feature_names"
      ],
      "metadata": {
        "id": "o5Pcalfe95Cr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def centrosomal_feature_names():\n",
        "  feature_names = classification.get_features_name(names_features_centrosome=True)\n",
        "  return feature_names"
      ],
      "metadata": {
        "id": "OqAtlf27961R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compute features\n",
        "def compute_features(cell_mask, nuc_mask, rna_coord, smfish, foci_coord):\n",
        "  features, features_names = classification.compute_features(\n",
        "      cell_mask, nuc_mask, ndim=3, rna_coord=rna_coord,\n",
        "      smfish=smfish, voxel_size_yx=103,\n",
        "      foci_coord=foci_coord,\n",
        "      centrosome_coord=None,\n",
        "      compute_distance=True,\n",
        "      compute_intranuclear=True,\n",
        "      compute_protrusion=True,\n",
        "      compute_dispersion=True,\n",
        "      compute_topography=True,\n",
        "      compute_foci=True,\n",
        "      compute_area=True,\n",
        "      return_names=True)\n",
        "  for feature, feature_name in zip(features, features_names):\n",
        "      print(\"{0:40} {1:0.2f}\".format(feature_name + \":\", feature))\n"
      ],
      "metadata": {
        "id": "JDwrYOiR99Pe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_number_from_filename(filename):\n",
        "    match = re.search(r'\\d{3}', filename)\n",
        "    if match:\n",
        "        return int(match.group())\n",
        "    else:\n",
        "        raise ValueError(f\"No 3-digit number found in the filename: {filename}\")\n"
      ],
      "metadata": {
        "id": "4BYv07EXyLk1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_images_interactively(path_output):\n",
        "    output_folder = os.path.join(path_output, 'output', 'extraction_results_npz_notebook6')\n",
        "    os.chdir(output_folder)\n",
        "\n",
        "    print(f\"Selected folder: {output_folder}\")\n",
        "\n",
        "    # Check if NPZ files are present in the current directory\n",
        "    npz_files = [f for f in os.listdir() if f.lower().endswith('.npz')]\n",
        "    print(f\"NPZ files found: {npz_files}\")\n",
        "\n",
        "    if not npz_files:\n",
        "        print(\"No NPZ files found in the current directory. Make sure you are in the correct directory.\")\n",
        "        return\n",
        "\n",
        "    dataframes = []\n",
        "\n",
        "    for npz_file in npz_files:\n",
        "        filename = os.path.join(output_folder, npz_file)\n",
        "\n",
        "        try:\n",
        "            # Extract cell index using the function\n",
        "            cell_index = extract_number_from_filename(npz_file)\n",
        "\n",
        "            # load single cell data\n",
        "            path = os.path.join(path_output, filename)\n",
        "            data = stack.read_cell_extracted(path)\n",
        "            cell_mask = data[\"cell_mask\"]\n",
        "            nuc_mask = data[\"nuc_mask\"]\n",
        "            rna_coord = data[\"rna_coord\"]\n",
        "            foci_coord = data[\"foci\"]\n",
        "            smfish = data[\"smfish\"]\n",
        "\n",
        "            # compute features\n",
        "            features, features_names = classification.compute_features(\n",
        "                cell_mask, nuc_mask, ndim=3, rna_coord=rna_coord,\n",
        "                smfish=smfish, voxel_size_yx=103,\n",
        "                foci_coord=foci_coord,\n",
        "                centrosome_coord=None,\n",
        "                compute_distance=True,\n",
        "                compute_intranuclear=True,\n",
        "                compute_protrusion=True,\n",
        "                compute_dispersion=True,\n",
        "                compute_topography=True,\n",
        "                compute_foci=True,\n",
        "                compute_area=True,\n",
        "                return_names=True\n",
        "            )\n",
        "\n",
        "            # build dataframe\n",
        "            features = features.reshape((1, -1))\n",
        "            df_cell = pd.DataFrame(data=features, columns=features_names)\n",
        "\n",
        "            # Add the cell index column\n",
        "            df_cell['cell_index'] = cell_index\n",
        "\n",
        "            dataframes.append(df_cell)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {npz_file}: {e}\")\n",
        "\n",
        "    # Define treatment name to be assigned in the final DataFrame\n",
        "    treatment_parts = top_level_folder.split(\"_\")\n",
        "\n",
        "    # Concatenate DataFrames\n",
        "    if dataframes:\n",
        "        df = pd.concat(dataframes, ignore_index=True)\n",
        "\n",
        "        # Set the cell index as the index of the DataFrame\n",
        "        df.set_index('cell_index', inplace=True)\n",
        "\n",
        "        # Save the concatenated DataFrame to a new CSV file\n",
        "        csv_filename = os.path.join(path_output, f'output_dataframe_{treatment_parts}.csv')\n",
        "        df.to_csv(csv_filename, index=True)  # Change index to True to include the cell_index column\n",
        "        print(f\"Final DataFrame saved to: {csv_filename}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Allow the user to choose a folder interactively\n",
        "    path_input = choose_folder_colab()\n",
        "\n",
        "    # Extract the name of the top-level folder\n",
        "    top_level_folder = os.path.basename(os.path.normpath(path_input))\n",
        "\n",
        "    if path_input:\n",
        "        # The user selected the treatment folder, so guide them in the \"output\" subfolder\n",
        "        process_images_interactively(path_input)"
      ],
      "metadata": {
        "id": "JhNJ2FgH1hBZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}